# Archive Module

The `archive` module is responsible for the collation of plant status data from the current day into an S3 bucket.

Files included within the module:

- `lambda_function/archive_pipeline`
  1. Fetches all plant status data contained within the specified RDS, specifying the desired columns.
  2. Writes the fetched tuple data to a CSV file `/tmp/YEAR/MONTH/DAY_hist.csv`
  3. Truncate the `plant_status` table to refresh the database for the upcoming day

- `lambda_function/Dockerfile`
  1. Copies the necessary python libraries to a python environment
  2. Creates a docker image using the script `archive_pipeline.py` 

- `archive_ecr_push.sh`
  1. Signs into aws using the `aws` CLI
  2. Builds, tags and pushes the new docker image to the remote ECR.
  *If the intended ecr `c15-cacareco-lmnh-plants-archive` is not used, replace the commands with those generated by the new ECR*

## Setup

1. Install Docker on your system. Ensure the docker daemon is running when attempting to dockerize.
2. Install and initialize terraform
3. Build terraform resources
```
terraform init
terraform plan # Preview changes
terraform apply
```

## Virtual Environment Installation
Install required libraries into a `venv`
```
pip install -r requirements.txt
```
Requirements:
- wheel
- pymssql 
- python-dotenv
- boto3

## Deployment
Requirements for deploying 
1. Running the terraform commands to create the required resources 
2. Create a remote ECR
3. Push the docker image to the remote ECR.
